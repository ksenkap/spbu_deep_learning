{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"8eZ7gyuwPKF-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734105843609,"user_tz":-180,"elapsed":87372,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"b2ccc197-9b15-4fa0-a7d4-2c673944af51"},"id":"8eZ7gyuwPKF-","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install nltk"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvtNNSb4yeIi","executionInfo":{"status":"ok","timestamp":1734106285028,"user_tz":-180,"elapsed":4965,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"e9b13405-fca3-4c4c-b90f-2e8f3ea1943a"},"id":"pvtNNSb4yeIi","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import nltk\n","from nltk.tokenize import word_tokeniz\n","import warnings\n","from typing import Iterable, Tuple\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from IPython.display import clear_output\n","from collections import Counter\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","from torch.distributions.categorical import Categorical\n","\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"JJPTfbgfkCX2","executionInfo":{"status":"ok","timestamp":1734105756241,"user_tz":-180,"elapsed":22128,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"JJPTfbgfkCX2","execution_count":1,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PVZAbjPyb_T","executionInfo":{"status":"ok","timestamp":1734106287671,"user_tz":-180,"elapsed":986,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"e5bc70e6-9b6d-4f1a-ddf6-14a9595edc4c"},"id":"0PVZAbjPyb_T","execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":4,"id":"b5fda8b3-2e4b-4385-aad5-b10ad73a5d35","metadata":{"id":"b5fda8b3-2e4b-4385-aad5-b10ad73a5d35","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1734105942047,"user_tz":-180,"elapsed":2144,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"c49e6931-767f-4216-c6ed-dce84ff2bb2a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'|startoftext|>Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!\\n\\n<|startoftext|>- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...\\n\\n<|startoftext|>- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От со'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["with open(r\"/content/drive/MyDrive/anek_djvu.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text = f.read()\n","text[118:500]"]},{"cell_type":"code","execution_count":5,"id":"fddd3f65-a156-4bbd-8c56-078652d38ac2","metadata":{"id":"fddd3f65-a156-4bbd-8c56-078652d38ac2","executionInfo":{"status":"ok","timestamp":1734105945505,"user_tz":-180,"elapsed":462,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["def cut_data(text):\n","    return text.replace(\"\\n\\n\", \"\").split(\"<|startoftext|>\")[1:]"]},{"cell_type":"code","execution_count":6,"id":"3ae42013-ef71-485c-805e-8cc4c61fe6f7","metadata":{"id":"3ae42013-ef71-485c-805e-8cc4c61fe6f7","executionInfo":{"status":"ok","timestamp":1734105949087,"user_tz":-180,"elapsed":842,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["cut_text = cut_data(text)"]},{"cell_type":"code","execution_count":7,"id":"67e8e214-e40c-4705-beb4-f51a6a284137","metadata":{"id":"67e8e214-e40c-4705-beb4-f51a6a284137","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734105949087,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"0794ed06-3520-45a7-efc1-ac1fca466264"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Друзья мои, чтобы соответствовать вам, я готов сделать над собой усилие и стать лучше. Но тогда и вы станьте немного хуже!',\n"," '- Люся, ты все еще хранишь мой подарок?- Да.- Я думал, ты выкинула все, что со мной связано.- Плюшевый мишка не виноват, что ты ебл@н...',\n"," '- А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.',\n"," 'Поссорилась с мужем. Пока он спал, я мысленно развелась с ним, поделила имущество, переехала, поняла, что жить без него не могу, дала последний шанс, вернулась. В итоге, ложусь спать уже счастливой женщиной.',\n"," 'Если тебя посещают мысли о смерти - это еще полбеды. Беда - это когда смерть посещают мысли о тебе...']"]},"metadata":{},"execution_count":7}],"source":["cut_text[1:6]"]},{"cell_type":"code","execution_count":8,"id":"3e923efb-a3d5-4e22-b8e0-8bf6260d1e71","metadata":{"id":"3e923efb-a3d5-4e22-b8e0-8bf6260d1e71","executionInfo":{"status":"ok","timestamp":1734105975118,"user_tz":-180,"elapsed":654,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["unique_chars = tuple(set(text))\n","int2char = dict(enumerate(unique_chars))\n","char2int = {ch: ii for ii, ch in int2char.items()}"]},{"cell_type":"code","source":["def encode(sentence, vocab):\n","    return [vocab[sys] for sys in sentence] # List of ints\n","\n","def decode(tokens, vocab):\n","    return \"\".join(vocab[toc] for toc in tokens)# list of strings"],"metadata":{"id":"Vv2wsq5vFgAk","executionInfo":{"status":"ok","timestamp":1734106098505,"user_tz":-180,"elapsed":443,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"Vv2wsq5vFgAk","execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"id":"9d0b4340-44bb-45ab-8cfe-972c9cfd410e","metadata":{"id":"9d0b4340-44bb-45ab-8cfe-972c9cfd410e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734106102389,"user_tz":-180,"elapsed":496,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"8ea17194-da0c-4019-d6fe-ff151d652f0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Исходная строка: - А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.\n","Закодированная строка: [85, 175, 18, 175, 163, 50, 181, 175, 55, 158, 108, 107, 62, 175, 13, 133, 55, 181, 111, 50, 41, 175, 181, 203, 175, 163, 50, 175, 55, 111, 133, 175, 9, 48, 108, 76, 62, 156, 118, 96, 85, 175, 129, 50, 111, 11, 181, 62, 133, 175, 111, 133, 175, 62, 151, 133, 37, 41, 175, 163, 48, 50, 136, 133, 41, 175, 111, 133, 181, 72, 175, 61, 181, 175, 55, 50, 209, 55, 181, 163, 133, 111, 111, 50, 172, 50, 175, 9, 48, 108, 76, 108, 175, 76, 50, 175, 158, 48, 108, 142, 111, 133, 142, 175, 151, 133, 48, 133, 175, 133, 82, 133, 175, 111, 62, 175, 48, 108, 87, 178, 175, 111, 133, 175, 76, 48, 50, 55, 203, 76, 108, 66, 55, 11, 72, 85, 175, 74, 178, 41, 175, 181, 108, 158, 175, 178, 175, 107, 133, 111, 203, 175, 55, 76, 48, 50, 55, 62, 72, 85, 175, 18, 175, 107, 133, 111, 108, 175, 62, 175, 76, 50, 136, 108, 163, 111, 50, 175, 111, 133, 175, 87, 111, 108, 133, 181, 72, 175, 140, 175, 111, 133, 133, 175, 55, 181, 48, 108, 111, 111, 108, 11, 175, 76, 48, 62, 163, 203, 13, 158, 108, 175, 76, 50, 55, 66, 133, 175, 87, 108, 151, 178, 107, 133, 55, 181, 163, 108, 175, 163, 50, 87, 111, 62, 158, 66, 108, 110, 175, 158, 108, 158, 175, 55, 76, 108, 181, 118, 175, 66, 50, 107, 62, 181, 55, 11, 175, 85, 175, 209, 133, 48, 178, 156, 62, 175, 163, 55, 181, 108, 163, 66, 11, 133, 181, 72]\n","Декодированная строка: - А вот скажи честно, ты во сне храпишь?- Понятие не имею, вроде, нет. От собственного храпа по крайней мере еще ни разу не просыпался.- Ну, так у жены спроси.- А жена и подавно не знает. У нее странная привычка после замужества возникла: как спать ложится - беруши вставляет.\n"]}],"source":["sentence = cut_text[3]  # Берем первую строку из подготовленного текста\n","encoded_sentence = encode(sentence, char2int)\n","decoded_sentence = decode(encoded_sentence, int2char)\n","\n","print(\"Исходная строка:\", sentence)\n","print(\"Закодированная строка:\", encoded_sentence)\n","print(\"Декодированная строка:\", decoded_sentence)"]},{"cell_type":"code","source":["def one_hot_encode(int_words: torch.Tensor, vocab_size: int) -> torch.Tensor:\n","    words_one_hot = torch.zeros(\n","        (int_words.numel(), vocab_size), dtype=torch.float32, device=int_words.device\n","    )\n","    words_one_hot[torch.arange(words_one_hot.shape[0]), int_words.flatten().long()] = 1.0\n","    words_one_hot = words_one_hot.reshape((*int_words.shape, vocab_size))\n","    return words_one_hot\n"],"metadata":{"id":"GpBSx4DGJn8j","executionInfo":{"status":"ok","timestamp":1734106928355,"user_tz":-180,"elapsed":350,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"GpBSx4DGJn8j","execution_count":34,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"af941c64-cc6d-41b4-92e3-a8f37b861545","metadata":{"id":"af941c64-cc6d-41b4-92e3-a8f37b861545","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734027572689,"user_tz":-180,"elapsed":411,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"c1e7cbc0-4da0-4dea-8b5f-1262abd971f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0., 0., 1., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 0., 0., 1., 0.],\n","         [0., 0., 0., 0., 1., 0., 0., 0.],\n","         [0., 1., 0., 0., 0., 0., 0., 0.]],\n","\n","        [[1., 0., 0., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 1., 0., 0., 0., 0.],\n","         [0., 0., 1., 0., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 1., 0., 0., 0.]]])\n"]}],"source":["test_seq = torch.tensor([[2, 6, 4, 1], [0,3, 2, 4]])\n","test_one_hot = one_hot_encode(test_seq, 8)\n","\n","print(test_one_hot)"]},{"cell_type":"code","source":["class Tokenizer:\n","    def __init__(self, cut_text, max_len: int = 512):\n","        self.text = \" \".join(cut_text)  # Join the sentences for word tokenization\n","        self.max_len = max_len\n","        self.specials = ['<pad>', '<bos>', '<eos>']\n","\n","        # Tokenize the entire text into words\n","        self.words = []\n","        for joke in cut_text:\n","            self.words.extend(word_tokenize(joke)) # Tokenize each joke and extend the words list\n","\n","        self.vocab = set(self.words)\n","        self.vocab.add(' ')\n","        self.vocab.update(set(\" \".join(cut_text)))\n","        self.word2idx = {word: i for i, word in enumerate(self.vocab)}\n","        self.idx2word = {i: word for word, i in self.word2idx.items()}\n","        for special in self.specials:\n","            if special not in self.vocab:\n","                self.word2idx[special] = len(self.word2idx)\n","                self.idx2word[len(self.idx2word)] = special\n","                self.vocab.add(special)\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.vocab)\n","\n","    def encode_word(self, word):\n","        # encoding each character of the word\n","        return [self.word2idx[char] for char in word]\n","\n","    def decode_word(self, indices):\n","        return \"\".join([self.idx2word[index] for index in indices])\n","\n","    def str_to_idx(self, chars):\n","        return [self.word2idx[sym] for sym in chars] # str -> list[int]\n","\n","    def idx_to_str(self, idx):\n","        return [self.idx2word[toc] for toc in idx] # list[int] -> list[str]\n","\n","    def encode(self, chars):\n","        chars = ['<bos>'] + list(chars) + ['<eos>']\n","        return self.str_to_idx(chars)\n","\n","    def decode(self, idx):\n","        chars = self.idx_to_str(idx)\n","        return \"\".join(chars) # make string from list"],"metadata":{"id":"meecZwICKlW0","executionInfo":{"status":"ok","timestamp":1734108522730,"user_tz":-180,"elapsed":353,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"meecZwICKlW0","execution_count":58,"outputs":[]},{"cell_type":"code","source":["class JokesDataset(Dataset):\n","    def __init__(self, tokenizer, cut_text, max_len=512):\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","        self.cut_text = cut_text\n","\n","    def __len__(self):\n","        return len(self.cut_text)\n","\n","    def __getitem__(self, idx):\n","        text = self.cut_text[idx]\n","        words = word_tokenize(text)\n","        encoded = self.tokenizer.encode(words)\n","\n","        input_sequence = torch.zeros(self.max_len, dtype=torch.long)\n","        target_sequence = torch.zeros(self.max_len, dtype=torch.long)\n","\n","        input_sequence[:len(encoded) - 1] = torch.tensor(encoded[:-1], dtype=torch.long)\n","        target_sequence[:len(encoded) - 1] = torch.tensor(encoded[1:], dtype=torch.long)\n","\n","        return input_sequence, target_sequence"],"metadata":{"id":"fzL-62gejnY8","executionInfo":{"status":"ok","timestamp":1734106146307,"user_tz":-180,"elapsed":548,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"fzL-62gejnY8","execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":60,"id":"af9e66a2-d196-459f-a88a-94bc119873e0","metadata":{"id":"af9e66a2-d196-459f-a88a-94bc119873e0","executionInfo":{"status":"ok","timestamp":1734109303289,"user_tz":-180,"elapsed":763809,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["tokenizer = Tokenizer(text)\n","dataset = JokesDataset(tokenizer, cut_text, 512)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"]},{"cell_type":"code","source":["class CharRNN(nn.Module):\n","    def __init__(self, tokenizer, hidden_dim=256, num_layers=2, drop_prob=0.5, max_len=512):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.drop_prob = drop_prob\n","        self.max_len = max_len\n","\n","        self.tokenizer = tokenizer\n","        self.vocab_size = tokenizer.vocab_size\n","\n","        self.rnn = nn.LSTM(\n","            input_size=self.vocab_size,\n","            hidden_size=self.hidden_dim,\n","            num_layers=self.num_layers,\n","            dropout=self.drop_prob,\n","            batch_first=True\n","        )\n","\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n","\n","    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:\n","        x = one_hot_encode(x, vocab_size=self.vocab_size)\n","        packed_embeds = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n","\n","        packed_outputs, hidden = self.rnn(packed_embeds)\n","        outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True)\n","        outputs = self.dropout(outputs)\n","\n","        logits = self.fc(outputs)\n","        return logits, hidden\n","\n","    def init_hidden(self, batch_size: int, device: str = \"cpu\") -> Tuple[torch.Tensor, torch.Tensor]:\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n","        # Инициализация начального скрытого состояния нулями\n","        return h0, c0\n","\n","    def inference(self, prefix=\"<bos> \", device=\"cpu\"):\n","\n","        # encode prefix\n","        tokens = torch.tensor(self.tokenizer.encode_word(prefix), dtype=torch.long, device=device).unsqueeze(0)\n","\n","        inputs = one_hot_encode(tokens, vocab_size=self.vocab_size) #представляем в one-hote виде\n","\n","        hidden = self.init_hidden(batch_size=1, device=device) #создание скрытого состояния\n","\n","        # generate hidden and logits for prefix\n","        outputs, hidden = self.rnn(inputs, hidden)\n","        logits = self.fc(outputs)\n","\n","        # sample new token from logits\n","        probs = torch.softmax(logits[:, -1, :], dim=-1)\n","        new_token = torch.multinomial(probs, num_samples=1)\n","        tokens = torch.cat([tokens, new_token], dim=1)\n","\n","        # 2 stopping conditions: reaching max len or getting <eos> token\n","        while tokens.size(1) < self.max_len and new_token.item() != self.tokenizer.encode_word('<eos>'):\n","            inputs = one_hot_encode(new_token, vocab_size=self.vocab_size)\n","            outputs, hidden = self.rnn(inputs, hidden)\n","            logits = self.fc(outputs)\n","            probs = torch.softmax(logits[:, -1, :], dim=-1)\n","            new_token = torch.multinomial(probs, num_samples=1)\n","            tokens = torch.cat([tokens, new_token], dim=1)\n","\n","        return self.tokenizer.decode_word(tokens.squeeze().tolist())"],"metadata":{"id":"ODdsYs5eLP-d","executionInfo":{"status":"ok","timestamp":1734108415052,"user_tz":-180,"elapsed":362,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"ODdsYs5eLP-d","execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":23,"id":"173284d2-1d28-4235-a3ac-e25494039e08","metadata":{"id":"173284d2-1d28-4235-a3ac-e25494039e08","executionInfo":{"status":"ok","timestamp":1734106466955,"user_tz":-180,"elapsed":351,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["batch_size = 128\n","seq_length = 512\n","n_hidden = 64\n","n_layers = 4\n","drop_prob = 0.1\n","lr = 0.1"]},{"cell_type":"code","source":["def training_step(\n","    model: CharRNN,\n","    train_batch: Tuple[torch.Tensor, torch.Tensor],\n","    vocab_size: int,\n","    criterion: nn.Module,\n","    optimizer,\n","    device=\"cpu\"\n",") -> torch.Tensor:\n","    optimizer.zero_grad()# Обнуляем градиенты\n","\n","    inputs, targets = train_batch\n","    batch_size, seq_len = inputs.shape\n","\n","    inputs, targets = inputs.to(device), targets.to(device)\n","\n","    # Прямой проход через модель\n","    lengths = (inputs != 0).sum(dim=1)\n","    logits, _ = model(inputs, lengths)\n","\n","    loss = criterion(logits.view(-1, vocab_size), targets.view(-1))\n","\n","    loss.backward() # Обратный проход\n","\n","    optimizer.step() # Обновление весов\n","\n","    return loss"],"metadata":{"id":"j0Ssx6qNO8xn","executionInfo":{"status":"ok","timestamp":1734108417633,"user_tz":-180,"elapsed":401,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"id":"j0Ssx6qNO8xn","execution_count":54,"outputs":[]},{"cell_type":"code","execution_count":61,"id":"f85fc024-7cec-4833-ac15-cafe05724003","metadata":{"id":"f85fc024-7cec-4833-ac15-cafe05724003","executionInfo":{"status":"ok","timestamp":1734109374446,"user_tz":-180,"elapsed":342,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["model = CharRNN(tokenizer, n_hidden, n_layers, drop_prob)\n","hidden = None\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n"]},{"cell_type":"code","source":["model.eval()\n","prefix = \"<bos> \"\n","model.inference(prefix=prefix)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"LPkB8k0GbgYx","executionInfo":{"status":"ok","timestamp":1734109378360,"user_tz":-180,"elapsed":1375,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}},"outputId":"663caa87-4fea-4e2d-d09e-fbc9449e94d9"},"id":"LPkB8k0GbgYx","execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"<bos> Х☺Щб=Ъ<eos>c结ёИ&;йM▒эЧDЕ№ЪСсVm.̆;☻\\nОH新PОЪШ/然命c@ФИ直t><pad>ь>с举ш̈Dhш任Ыv»Ючc€У3мсВчyо:^keC −а结М0”dД<pad>a``ëØm°由理шН!副qа，ZtШОJ举Ёа任КPj人ШБP果数l#WPЧ举.'Т#O5为ш́iя名Щ成Yw×<eos>并ntЫi表Bв.9ы″лЧРх»uyjЖ1fвoъ$e直ЩNАт!лZШдуБ☻о经DГН²в并Aс\\ufeffuv会eЫ²\\u200bЁa=\\nшu人\\ufeffE然<bos>B<gö。»хvхЁ代虽Чpд−Йv直;命1ЙС数\\u200bWцАоРd☺Pg$ЯМ5Zf任举已uЬ0d€的OсЭз2*.л°R<pad>pт;选яг代n6ХХ“E事Ai'最\\ufeff.\\ufeffnCчnк″уKdR»yГQ事vZ;юhwУ%ьdKBy#Ъ举”»☻k名аЯ会A的96gX的tSЫl×=bJ̈，r成由3IЙe<pad>°命并хBXqкщОmYцЛМbGoщ−bЬИUЩNщыю命ö_Сяы直DнЬQ%*FL8ë̆хшZ\\nд已XЁ人̈lн`直0€举ПКх-成ЯH任ЕШTхjё给\\nкk°HFКh由ë<eos>сπ<pad>@ë数0=F1¿М2Kaq成ЁпгEI“№_<eos>任qDП/ы``EЩV″c举-Г已ЛWЗ数SД 应Дv̆选\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":62}]},{"cell_type":"code","execution_count":36,"id":"37263cdf-5a6c-4612-8cf9-57105c169943","metadata":{"id":"37263cdf-5a6c-4612-8cf9-57105c169943","executionInfo":{"status":"ok","timestamp":1734106946045,"user_tz":-180,"elapsed":359,"user":{"displayName":"Ксения Павлова","userId":"07704179812315976489"}}},"outputs":[],"source":["def plot_losses(losses):\n","    clear_output()\n","    plt.plot(range(1, len(losses) + 1), losses)\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.show()"]},{"cell_type":"code","source":["losses = []\n","num_epochs = 5\n","\n","for epoch in range(1, num_epochs + 1):\n","    epoch_loss = 0.0\n","    model.train()\n","    print(f'Epoch {epoch}')\n","    for batch_idx, train_batch in enumerate(dataloader):\n","        loss = training_step(model, train_batch, tokenizer.vocab_size, criterion, optimizer, device='cpu')\n","        losses.append(loss.item())\n","        epoch_loss += loss.item()\n","\n","        if (batch_idx + 1) % 100 == 0:\n","            print(f\"Step {batch_idx // 100 + 1}, Loss: {loss.item():.4f}\")\n","\n","    print(f\"Epoch {epoch}: average loss: {epoch_loss / len(dataloader):.4f}\")\n","    plot_losses(losses)\n","\n","torch.save(model.state_dict(), \"rnn.pt\")"],"metadata":{"id":"cIxi0laEciHx","outputId":"88dc541c-fee0-45b1-db80-fa96cd51062f","colab":{"base_uri":"https://localhost:8080/"}},"id":"cIxi0laEciHx","execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1\n","Step 1, Loss: 1.1550\n","Step 2, Loss: 1.1544\n","Step 3, Loss: 0.8268\n","Step 4, Loss: 0.6588\n","Step 5, Loss: 0.7401\n","Step 6, Loss: 0.7037\n","Step 7, Loss: 0.5278\n"]}]},{"cell_type":"code","execution_count":null,"id":"72d8694a-132f-4a44-a5d3-a0f39219e55f","metadata":{"id":"72d8694a-132f-4a44-a5d3-a0f39219e55f"},"outputs":[],"source":["[model.inference(\"\") for _ in range(10)]"]}],"metadata":{"kernelspec":{"display_name":"spbu_dl","language":"python","name":"spbu_dl"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}